{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "014bafd1",
   "metadata": {},
   "source": [
    "# Data Cleaning and Preparation Notebook\n",
    "\n",
    "This notebook focuses on the initial stages of the data analytics pipeline. Here, we'll perform the following key tasks:\n",
    "- Import necessary libraries and set initial configurations.\n",
    "- Collect and validate user inputs regarding stock analysis preferences.\n",
    "- Retrieve stock data and related metrics from the Alphavantage API.\n",
    "- Perform preliminary data cleaning and validation.\n",
    "\n",
    "The cleaned data will serve as the foundation for subsequent analysis and modeling in the later notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33804c47",
   "metadata": {},
   "source": [
    "### Library Imports and Initial Setup\n",
    "\n",
    "In this section, we import all the necessary libraries and set up initial configurations. This prepares our environment for data analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b76d81f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.optimize as sco\n",
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddd8800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default stock tickers and index for analysis, these will be the default choice if user didn't provide any from their side.\n",
    "\n",
    "test_list = ['AAPL', 'ORCL', 'NVDA']\n",
    "index = ['SPY']\n",
    "\n",
    "term = 'short'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd426825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a list of valid stock tickers from a file.\n",
    "\n",
    "# Note: Within this project, we are currently only be able to accept stocks listed on the S&P 500.\n",
    "with open('stock ticker', 'r') as file:\n",
    "    valid_tickers = set(file.read().splitlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1301b7f",
   "metadata": {},
   "source": [
    "### User Input and Data Validation\n",
    "\n",
    "Here, we prompt the user to select the desired time interval and stock tickers for analysis. We also validate the chosen stock tickers against a predefined list.\n",
    "\n",
    "- It promt the user to choose between a 'long' or 'short' time interval for anlalyse.\n",
    "- it will also want the user to choose what stocsk they want to analyse, with a max limit of 3 stocks.\n",
    "- if not input were give, it will have a default value of short, and stock list of: 'AAPL', 'ORCL', 'NVDA'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39b4ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a given stock ticker is valid.\n",
    "\n",
    "def is_valid_ticker(ticker):\n",
    "    return ticker.upper() in valid_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23f306e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter 'short' or 'long' for the time interval you want to analyse data for(or press Enter to use the default): \n",
      "You have selected: short\n"
     ]
    }
   ],
   "source": [
    "# Here, we want to know if the user want to use long term data, or a short term data.\n",
    "user_input = input(\"Enter 'short' or 'long' for the time interval you want to analyse data for(or press Enter to use the default): \")\n",
    "\n",
    "while user_input not in ['long', 'short', '']:\n",
    "    print(\"Invalid input. Please enter either 'long', 'short', or press Enter to use the default.\")\n",
    "    user_input = input(\"Enter the term to work with ('long', 'short' or press Enter to use the default): \").lower()\n",
    "\n",
    "# Check if the user pressed Enter without typing anything, this will mean the term will set to short by default:\n",
    "if user_input == \"\":\n",
    "    pass\n",
    "else:\n",
    "    # Otherwise, use the user's input\n",
    "    term = user_input\n",
    "\n",
    "print(f\"You have selected: {term}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c447332e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the stock ticker for stock (or press Enter to use the default) 1: \n",
      "you have choosed the default stock list\n",
      "You have choosed the following stock tickers: AAPL, ORCL, NVDA\n"
     ]
    }
   ],
   "source": [
    "# Here, we attempt to collect stock tickers from the user.\n",
    "# If the user doesn't specify any ticker, the default list is used.\n",
    "\n",
    "list_copy = test_list.copy()\n",
    "default_use = False\n",
    "\n",
    "# Loop three times to collect three stock tickers\n",
    "for i in range(1, 4):\n",
    "    # Prompt the user for a stock ticker\n",
    "    ticker = input(f\"Enter the stock ticker for stock (or press Enter to use the default) {i}: \")\n",
    "    \n",
    "    if ticker == \"\":\n",
    "        print(\"you have choosed the default stock list\")\n",
    "        default_use = True\n",
    "        break\n",
    "        \n",
    "    # Validaing the user input using the pre define function:\n",
    "    while not is_valid_ticker(ticker):\n",
    "        print(\"Invalid ticker. Please try again.\")\n",
    "        ticker = input(\"Enter a stock ticker: \") \n",
    "        \n",
    "    # Add the ticker to the list\n",
    "    list_copy[i-1] = (ticker.upper())  # Assuming tickers should be uppercase\n",
    "\n",
    "# Now stock_tickers contains the three tickers entered by the user\n",
    "if default_use == True:\n",
    "    list_copy = test_list.copy()\n",
    "    \n",
    "print(f\"You have choosed the following stock tickers: {', '.join(list_copy)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61c8a13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we ensure that we also get data for the market index.\n",
    "list_copy = list_copy + index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e2849",
   "metadata": {},
   "source": [
    "### Data Retrieval from Alphavantage API\n",
    "\n",
    "In this section, we define functions to fetch stock data, market data, and risk-free rate data from the Alphavantage API. This data is crucial for our subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65d50537",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below are the functions to fetch stock and risk free rate data from Alphavantage API based on the chosen term.\n",
    "# Data is fetched for each stock in the list.\n",
    "# API rate limits are respected by introducing sleep between requests.\n",
    "\n",
    "def get_price(term):\n",
    "    \n",
    "    # Note: The API from alphavintage will need the user to get their own.\n",
    "    # Here, I have used my own which is saved in my local machine. \n",
    "    key_alpha = os.environ.get('KEY_ALPHA') \n",
    "    BASE_URL = 'https://www.alphavantage.co/query?'\n",
    "    data = {}\n",
    "    \n",
    "    if term == 'short':\n",
    "        function = 'TIME_SERIES_DAILY'\n",
    "    else:\n",
    "        function = 'TIME_SERIES_MONTHLY'\n",
    "        \n",
    "    for stock in list_copy:\n",
    "        params = {\n",
    "                  'function': function,\n",
    "                  'symbol': stock,\n",
    "                  'apikey': key_alpha\n",
    "                 }\n",
    "\n",
    "        response = requests.get(BASE_URL, params = params)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data[stock] = response.json()  # get data succuse\n",
    "\n",
    "            # Respect the rate limit from alpha vintage. (Note: this is what slowing down the run speed of the file)\n",
    "            time.sleep(15)\n",
    "        \n",
    "        else:\n",
    "            print(f\"Failed to retrieve data for {stock}. Status code: {response.status_code}\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cc2ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting risk free rate data:\n",
    "\n",
    "def get_rf(term):\n",
    "\n",
    "    key_alpha = os.environ.get('KEY_ALPHA')\n",
    "    BASE_URL = 'https://www.alphavantage.co/query?'\n",
    "    data = {}\n",
    "    \n",
    "    if term == 'short':\n",
    "        interval = 'daily'\n",
    "    else:\n",
    "        interval = 'monthly'\n",
    "    \n",
    "    params_yield = {\n",
    "        'function': 'TREASURY_YIELD',\n",
    "        'apikey': key_alpha,\n",
    "        'interval': interval\n",
    "                    }\n",
    "    response = requests.get(BASE_URL, params = params_yield)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "            data = response.json()  # get data succuse\n",
    "        \n",
    "    else:\n",
    "        print(f\"Failed to retrieve data. Status code: {response.status_code}\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e14ddb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_range_fix(term, data):\n",
    "    if term == 'short':\n",
    "        cutoff_date = '2023-07-31'\n",
    "        data = data[data['date'] <= cutoff_date]\n",
    "    \n",
    "    else:\n",
    "        cutoff_date1 = '2023-07-31'\n",
    "        cutoff_date2 = '2013-07-31'\n",
    "        data = data[data['date'] <= cutoff_date1 & data['date'] >= cutoff_date2]\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa9c6524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming and formatting the fetched stock data into a structured DataFrame.\n",
    "# Data for individual stocks is concatenated, and columns are standardized.\n",
    "\n",
    "# Getting stock data:\n",
    "stock_data = get_price(term)\n",
    "\n",
    "# Getting risk free rate data:\n",
    "rf_data = get_rf(term)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180869ff",
   "metadata": {},
   "source": [
    "### Loading and Preparing Factor Data\n",
    "\n",
    "We load factors data required for our models from CSV files. This includes data for both the Fama model and the Momentum model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "867e2ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting factors data for fama model:\n",
    "new_factor = pd.read_csv('F-F_Research_Data_Factors_daily.CSV', delimiter = ',', parse_dates = ['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b146333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting factor data for momentum model:\n",
    "mom_factor = pd.read_csv('F-F_Momentum_Factor_daily.CSV', delimiter = ',', parse_dates = ['date'])\n",
    "\n",
    "# Here, to prevent the parse_dates function with pd from not working sometime with different date format, we need to convert it ourself\n",
    "mom_factor['date'] = pd.to_datetime(mom_factor['date'], format='%Y%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0efdcaf",
   "metadata": {},
   "source": [
    "### Data Formatting and Transformation\n",
    "\n",
    "The raw data retrieved and loaded in previous steps is transformed into structured DataFrames. We ensure that the data is in the correct format and structure for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a403843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing data cleaning tasks, renaming columns, and adjusting the date range based on the chosen term.\n",
    "\n",
    "frame_list = []\n",
    "\n",
    "for ticker, datas in stock_data.items():\n",
    "    df = pd.DataFrame(datas['Time Series (Daily)']).T\n",
    "    df['ticker'] = ticker  # add ticker column for the each stock\n",
    "    df = df.reset_index().rename(columns = {'index': 'date'})  # Reset the index and rename it to \"date\"\n",
    "    df['date'] = pd.to_datetime(df['date'])  # Convert the date column to datetime format\n",
    "    frame_list.append(df)  # Append the DataFrame to the list\n",
    "\n",
    "\n",
    "# After extracting needed data from the pulled data, we can now build them into one dataframe:\n",
    "combine = pd.concat(frame_list[0:3]) # we only use the first 3, because the last one is the index\n",
    "\n",
    "market_return = frame_list[-1] # this is the index, we will deal with it more in later part.\n",
    "\n",
    "\n",
    "# Give new columns name:\n",
    "column_name = ['date', 'open', 'high', 'low', 'close', 'volumn', 'ticker']\n",
    "combine.columns = column_name\n",
    "market_return.columns = column_name\n",
    "\n",
    "\n",
    "# Changing types so that we can make calculation with our datas:\n",
    "combine.iloc[:, 2:6] = combine.iloc[:, 2:6].astype(float)\n",
    "market_return.iloc[:, 2:6] = market_return.iloc[:, 2:6].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fbc3b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date type conversion for risk free rate dataframe as well:\n",
    "rf_data = pd.DataFrame(rf_data['data'])\n",
    "rf_data['date'] = pd.to_datetime(rf_data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87478f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the dataframe use for latter part of this project:\n",
    "\n",
    "backtesting_data = combine[(combine['date'].dt.year == 2023) & ((combine['date'].dt.month == 8) | (combine['date'].dt.month == 9))]\n",
    "backtesting_data = backtesting_data.iloc[::-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6dd2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the stock data and index data:\n",
    "merged_data = combine.merge(rf_data, on = 'date', how = 'left').merge(market_return[['date','close']], on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bfe4ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix up only small detail:\n",
    "\n",
    "merged_data['value'] = merged_data['value'].astype(float) / 100 # have the risk free rate in numeric form, rather than percent form.\n",
    "\n",
    "# Renaming some of the columns:\n",
    "merged_data = merged_data.rename(columns = {'value': 'rf'})\n",
    "merged_data = merged_data.rename(columns = {'close_y': 'market'})\n",
    "\n",
    "# Set the date range for our dataframe using the date_range_fix( function we defined above:\n",
    "merged_data = date_range_fix(term, merged_data)\n",
    "merged_data = merged_data.iloc[::-1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd80a9",
   "metadata": {},
   "source": [
    "### Computing Returns and Excess Returns\n",
    "\n",
    "In this section, we compute daily returns for the selected stocks and the market. We also calculate the excess returns by considering the risk-free rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04191ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the daliy return:\n",
    "merged_data[\"ret\"] = merged_data.groupby('ticker')['close_x'].apply(lambda x: x.pct_change(1))\n",
    "merged_data[\"mkret\"] = merged_data.groupby('ticker')['market'].apply(lambda x: x.pct_change(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c069357b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting excess returns:\n",
    "merged_data['ex_return'] = merged_data['ret'] - merged_data['rf']\n",
    "merged_data['mkt_ex_return'] = merged_data['mkret'] - merged_data['rf']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a0c64c",
   "metadata": {},
   "source": [
    "### Merging All Relevant Data\n",
    "\n",
    "Finally, we merge all the relevant data sources (stock data, risk-free rate, market returns, and factors data) into a single comprehensive dataset. This dataset forms the basis for any subsequent analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc95a4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging all factors data needed:\n",
    "final_data = merged_data.merge(new_factor[['date', 'SMB', 'HML']], on = 'date', how = 'left').merge(mom_factor[['date', 'Mom']], on = 'date', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b188e69",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfinal_data\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'final_data' is not defined"
     ]
    }
   ],
   "source": [
    "final_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
